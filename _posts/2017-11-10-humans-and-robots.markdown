---
layout: post
title:  "Humans and robots"
date:   2017-11-10 11:25:43 +0100
categories: humans robots
---
One part of our examination is to add two textdocuments called [*humans.txt*](humantxt.org) and [*robots.txt*](robotstxt.org). These files
exist to provide additional info to users of the site, wether it's a person or a bot traversing the internet.

The purpose of the *humans.txt* is to give the user a way to get information about people, software and standards that have been used on
the site. In our *humans.txt* I mention which software I've used, and also provides my email adress and more if a user would like to contact
me.

On the web there's not only humans browsing. There's also programmed bots to gather information about the site, f.e Google, that uses a bot 
to help caching the site and makes it searchable. In our project our *robots.txt* contains some lines that tell all the bots that checks the 
site to ignore it, by not giving them permission for any files or folders. I did this because this is only a temporary project site, and doesn't need to  
be cached.
